# AI 模型监控功能总结

## 一、概述

monitor 包实现了基于 Micrometer 和 LangChain4j 的 AI 模型监控系统，用于收集和分析 AI 模型调用的各项指标数据。

## 二、核心组件

### 2.1 组件关系图

```mermaid
classDiagram
    class MonitorContext {
        <<Serializable>>
        +String userId
        +String appId
    }

    class MonitorContextHolder {
        <<ThreadLocal>>
        -ThreadLocal~MonitorContext~ CONTEXT_HOLDER
        +setContext(MonitorContext)
        +getContext() MonitorContext
        +clearContext()
    }

    class AiModelMetricsCollector {
        -MeterRegistry meterRegistry
        -ConcurrentMap requestCountersCache
        -ConcurrentMap errorCountersCache
        -ConcurrentMap tokenCountersCache
        -ConcurrentMap responseTimersCache
        +recordRequest(userId, appId, modelName, status)
        +recordError(userId, appId, modelName, errorMessage)
        +recordTokenUsage(userId, appId, modelName, tokenType, tokenCount)
        +recordResponseTime(userId, appId, modelName, duration)
    }

    class AiModelMonitorListener {
        <<ChatModelListener>>
        -AiModelMetricsCollector aiModelMetricsCollector
        -REQUEST_START_TIME_KEY
        -MONITOR_CONTEXT_KEY
        +onRequest(ChatModelRequestContext)
        +onResponse(ChatModelResponseContext)
        +onError(ChatModelErrorContext)
    }

    MonitorContextHolder --> MonitorContext : 管理
    AiModelMonitorListener --> AiModelMetricsCollector : 委托
    AiModelMonitorListener --> MonitorContextHolder : 获取上下文
```

### 2.2 组件说明

| 组件 | 职责 |
|------|------|
| **MonitorContext** | 监控上下文实体，包含 userId 和 appId 等业务信息 |
| **MonitorContextHolder** | 基于 ThreadLocal 的上下文管理器，在同一线程中传递监控数据 |
| **AiModelMetricsCollector** | 指标收集器，使用 Micrometer 框架注册和记录各类监控指标 |
| **AiModelMonitorListener** | 实现 LangChain4j 的 ChatModelListener 接口，在模型调用各阶段触发指标收集 |

## 三、监控指标

### 3.1 指标体系

```mermaid
graph TB
    subgraph 监控指标
        A[请求次数<br/>ai_model_requests_total]
        B[错误次数<br/>ai_model_errors_total]
        C[Token消耗<br/>ai_model_tokens_total]
        D[响应时间<br/>ai_model_response_duration_seconds]
    end

    A --> A1[标签: user_id, app_id,<br/>model_name, status]
    B --> B1[标签: user_id, app_id,<br/>model_name, error_message]
    C --> C1[标签: user_id, app_id,<br/>model_name, token_type]
    D --> D1[标签: user_id, app_id,<br/>model_name]
```

### 3.2 指标详情

| 指标名称 | 类型 | 描述 | 标签维度 |
|----------|------|------|----------|
| `ai_model_requests_total` | Counter | AI 模型总请求次数 | user_id, app_id, model_name, status |
| `ai_model_errors_total` | Counter | AI 模型错误次数 | user_id, app_id, model_name, error_message |
| `ai_model_tokens_total` | Counter | AI 模型 Token 消耗总数 | user_id, app_id, model_name, token_type |
| `ai_model_response_duration_seconds` | Timer | AI 模型响应时间 | user_id, app_id, model_name |

## 四、监控流程

### 4.1 完整流程图

```mermaid
sequenceDiagram
    participant Client as 客户端
    participant Interceptor as 拦截器/AOP
    participant Holder as MonitorContextHolder
    participant Service as 业务Service
    participant Listener as AiModelMonitorListener
    participant Collector as AiModelMetricsCollector
    participant MeterRegistry as Micrometer
    participant AI as AI模型

    Client->>Interceptor: 请求 (携带userId, appId)
    Interceptor->>Holder: setContext(userId, appId)
    activate Holder
    Note over Holder: ThreadLocal存储上下文

    Interceptor->>Service: 调用业务方法
    Service->>AI: 调用AI模型

    Note over Listener: onRequest 触发
    Listener->>Holder: getContext()
    Holder-->>Listener: 返回 MonitorContext
    Listener->>Listener: 记录请求开始时间
    Listener->>Collector: recordRequest(status="started")
    Collector->>MeterRegistry: 注册/递增计数器

    AI-->>Service: 返回响应 (或抛出异常)

    alt 请求成功
        Note over Listener: onResponse 触发
        Listener->>Listener: 从 attributes 获取上下文
        Listener->>Collector: recordRequest(status="success")
        Listener->>Collector: recordResponseTime()
        Listener->>Collector: recordTokenUsage()
        Collector->>MeterRegistry: 记录各类指标
    else 请求失败
        Note over Listener: onError 触发
        Listener->>Holder: getContext()
        Listener->>Collector: recordRequest(status="error")
        Listener->>Collector: recordError()
        Listener->>Collector: recordResponseTime()
        Collector->>MeterRegistry: 记录错误指标
    end

    Service-->>Interceptor: 返回结果
    Interceptor->>Holder: clearContext()
    deactivate Holder
    Interceptor-->>Client: 响应
```

### 4.2 上下文传递流程

```mermaid
flowchart TB
    subgraph Phase1["阶段1: 入口设置"]
        direction TB
        A1["用户请求<br/>携带 userId, appId"]
        A2["拦截器/AOP"]
        A3["MonitorContextHolder.setContext"]
        A1 --> A2 --> A3
    end

    subgraph Phase2["阶段2: ThreadLocal存储"]
        direction TB
        B1["ThreadLocal<MonitorContext>"]
        B2["存储 userId, appId"]
        A3 --> B1
        B1 --> B2
    end

    subgraph Phase3["阶段3: AI调用开始"]
        direction TB
        C1["AiModelMonitorListener.onRequest"]
        C2["从 ThreadLocal 获取 MonitorContext"]
        C3["存入 ChatModelRequestContext.attributes()"]
        C4["记录请求开始时间"]
        B2 --> C1
        C1 --> C2 --> C3 --> C4
    end

    subgraph Phase4["阶段4: AI响应处理"]
        direction TB
        D1["AiModelMonitorListener.onResponse/onError"]
        D2["从 attributes 获取上下文"]
        D3["计算响应耗时"]
        D4["AiModelMetricsCollector 记录指标"]
        C4 --> D1
        D1 --> D2 --> D3 --> D4
    end

    subgraph Phase5["阶段5: 清理"]
        direction TB
        E1["MonitorContextHolder.clearContext"]
        E2["清除 ThreadLocal"]
        D4 --> E1 --> E2
    end

    style Phase1 fill:#e1f5fe
    style Phase2 fill:#fff3e0
    style Phase3 fill:#f3e5f5
    style Phase4 fill:#e8f5e9
    style Phase5 fill:#ffebee
```

## 五、数据流转

### 5.1 参数传递机制

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        参数传递流程                                       │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. 入口: 用户请求携带 userId/appId                                        │
│         ↓                                                               │
│  2. ThreadLocal存储: AOP/拦截器将 userId/appId 存入 MonitorContextHolder   │
│         ↓                                                               │
│  3. onRequest: 从 MonitorContext(ThreadLocal) 取出 userId/appId,         │
│                存入 ChatModelRequestContext.attributes()                 │
│         ↓                                                               │
│  4. onResponse: 从 ChatModelResponseContext.attributes() 取出数据,        │
│                计算耗时并记录指标                                           │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 两个上下文概念

| 上下文类型 | 来源 | 用途 | 生命周期 |
|-----------|------|------|----------|
| **ChatModelRequestContext/ResponseContext** | LangChain4j | 在 onRequest/onResponse/onError 之间传递数据 | 单次模型调用 |
| **MonitorContext** | 自定义 | 包含 userId、appId 等业务信息 | 单次 HTTP 请求 |

## 六、性能优化

### 6.1 指标缓存机制

```mermaid
graph TB
    A[recordRequest 调用] --> B{缓存Key存在?}
    B -->|否| C[创建 Counter]
    B -->|是| D[复用已有 Counter]
    C --> E[存入 ConcurrentHashMap]
    D --> F[Counter.increment]
    E --> F
    F --> G[Micrometer MeterRegistry]

    style C fill:#f9f,stroke:#333
    style D fill:#9f9,stroke:#333
```

### 6.2 缓存策略

- 使用 `ConcurrentHashMap` 缓存已创建的指标对象
- 通过 `computeIfAbsent` 方法实现原子性的"检查-创建"操作
- 避免重复注册相同维度的指标，提升性能

## 七、关键代码位置

| 文件 | 行号 | 说明 |
|------|------|------|
| `MonitorContext.java` | 全部 | 监控上下文实体 |
| `MonitorContextHolder.java` | 22-43 | ThreadLocal 上下文管理 |
| `AiModelMetricsCollector.java` | 48-60 | 请求次数记录 |
| `AiModelMetricsCollector.java` | 71-83 | 错误次数记录 |
| `AiModelMetricsCollector.java` | 94-107 | Token 消耗记录 |
| `AiModelMetricsCollector.java` | 119-130 | 响应时间记录 |
| `AiModelMonitorListener.java` | 50-62 | onRequest 处理 |
| `AiModelMonitorListener.java` | 65-80 | onResponse 处理 |
| `AiModelMonitorListener.java` | 83-97 | onError 处理 |